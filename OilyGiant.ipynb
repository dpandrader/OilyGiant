{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id        f0        f1        f2     product\n",
      "0      txEyH  0.705745 -0.497823  1.221170  105.280062\n",
      "1      2acmU  1.334711 -0.340164  4.365080   73.037750\n",
      "2      409Wp  1.022732  0.151990  1.419926   85.265647\n",
      "3      iJLyR -0.032172  0.139033  2.978566  168.620776\n",
      "4      Xdl7t  1.988431  0.155413  4.751769  154.036647\n",
      "...      ...       ...       ...       ...         ...\n",
      "99995  DLsed  0.971957  0.370953  6.075346  110.744026\n",
      "99996  QKivN  1.392429 -0.382606  1.273912  122.346843\n",
      "99997  3rnvd  1.029585  0.018787 -1.348308   64.375443\n",
      "99998  7kl59  0.998163 -0.528582  1.583869   74.040764\n",
      "99999  1CWhH  1.764754 -0.266417  5.722849  149.633246\n",
      "\n",
      "[100000 rows x 5 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Lectura de dataset data_0\n",
    "\n",
    "data_0= pd.read_csv('geo_data_0.csv', sep=',')\n",
    "print(data_0)\n",
    "data_0.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id         f0         f1        f2     product\n",
      "0      kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
      "1      62mP7  14.272088  -3.475083  0.999183   26.953261\n",
      "2      vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
      "3      KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
      "4      AHL4O  12.702195  -8.147433  5.004363  134.766305\n",
      "...      ...        ...        ...       ...         ...\n",
      "99995  QywKC   9.535637  -6.878139  1.998296   53.906522\n",
      "99996  ptvty -10.160631 -12.558096  5.005581  137.945408\n",
      "99997  09gWa  -7.378891  -3.084104  4.998651  137.945408\n",
      "99998  rqwUm   0.665714  -6.152593  1.000146   30.132364\n",
      "99999  relB0  -3.426139  -7.794274 -0.003299    3.179103\n",
      "\n",
      "[100000 rows x 5 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Lectura de dataset data_1\n",
    "\n",
    "data_1= pd.read_csv('geo_data_1.csv', sep=',')\n",
    "print(data_1)\n",
    "data_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id        f0        f1        f2     product\n",
      "0      fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
      "1      WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
      "2      ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
      "3      q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
      "4      WPMUX -0.515993  1.716266  5.899011  149.600746\n",
      "...      ...       ...       ...       ...         ...\n",
      "99995  4GxBu -1.777037  1.125220  6.263374  172.327046\n",
      "99996  YKFjq -1.261523 -0.894828  2.524545  138.748846\n",
      "99997  tKPY3 -1.199934 -2.957637  5.219411  157.080080\n",
      "99998  nmxp2 -2.419896  2.417221 -5.548444   51.795253\n",
      "99999  V9kWn -2.551421 -2.025625  6.090891  102.775767\n",
      "\n",
      "[100000 rows x 5 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Lectura de dataset data_2\n",
    "\n",
    "data_2= pd.read_csv('geo_data_2.csv', sep=',')\n",
    "print(data_2)\n",
    "data_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al revisar cada conjunto de datos, se constató que todos ellos comparten una estructura común: cinco columnas. La primera columna, identificada como 'id', contiene valores alfanuméricos y, por ende, tiene un tipo de dato 'object'. Las cuatro columnas restantes almacenan valores numéricos decimales, lo que justifica su tipo de dato 'float64'. Cada conjunto de datos cuenta con 100,000 registros. Cabe destacar que no se detectaron valores faltantes en ninguno de ellos, por lo que no fue necesario implementar ninguna técnica de preprocesamiento para tratar datos nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de entrenamiento data_0: (75000, 3)\n",
      "Tamaño de validación_ data_0: (25000,)\n",
      "\n",
      "\n",
      "Tamaño de entrenamiento data_1: (75000, 3)\n",
      "Tamaño de validación_ data_1: (25000,)\n",
      "\n",
      "\n",
      "Tamaño de entrenamiento data_2: (75000, 3)\n",
      "Tamaño de validación_ data_2: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Segmentacion de todos los datos\n",
    "\n",
    "def segmentacion_datos(info):\n",
    "    features = info.drop(['id','product'] ,axis=1)\n",
    "    target = info['product']\n",
    "\n",
    "    return train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "    \n",
    "features_train_0, features_valid_0, target_train_0, target_valid_0 = segmentacion_datos(data_0)\n",
    "features_train_1, features_valid_1, target_train_1, target_valid_1 = segmentacion_datos(data_1)\n",
    "features_train_2, features_valid_2, target_train_2, target_valid_2 = segmentacion_datos(data_2)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Tamaño de entrenamiento data_0: {features_train_0.shape}')\n",
    "print(f'Tamaño de validación_ data_0: {target_valid_0.shape}')\n",
    "print('\\n')\n",
    "print(f'Tamaño de entrenamiento data_1: {features_train_1.shape}')\n",
    "print(f'Tamaño de validación_ data_1: {target_valid_1.shape}')\n",
    "print('\\n')\n",
    "print(f'Tamaño de entrenamiento data_2: {features_train_2.shape}')\n",
    "print(f'Tamaño de validación_ data_2: {target_valid_2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos fueron divididos aleatoriamente en un conjunto de entrenamiento (75%) y un conjunto de validación (25%) para permitir la evaluación del modelo durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo de regresión lineal en el conjunto de validación: 6.130205682934407\n",
      "\n",
      "\n",
      "RMSE del modelo de regresión lineal en el conjunto de validación: 0.9450393043549125\n",
      "\n",
      "\n",
      "RMSE del modelo de regresión lineal en el conjunto de validación: 6.326903566037208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 93.59963303,  75.10515854,  90.06680936, ...,  99.40728116,\n",
       "        77.77991248, 129.03241718])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelos de Regresión Líneal \n",
    "\n",
    "def modelo_regresion_lineal(features_train, target_train, features_valid , target_valid):\n",
    "\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(features_train, target_train) \n",
    "    predictions_valid = model.predict(features_valid) \n",
    "    \n",
    "    score= root_mean_squared_error(target_valid, predictions_valid)**0.5\n",
    "    print(\"RMSE del modelo de regresión lineal en el conjunto de validación:\", score)\n",
    "    \n",
    "    return predictions_valid\n",
    "\n",
    "predictions_0 = modelo_regresion_lineal(features_train_0, target_train_0, features_valid_0, target_valid_0)\n",
    "predictions_0\n",
    "print('\\n')\n",
    "predictions_1 = modelo_regresion_lineal(features_train_1, target_train_1, features_valid_1, target_valid_1) \n",
    "predictions_1\n",
    "print('\\n')\n",
    "predictions_2 = modelo_regresion_lineal(features_train_2, target_train_2, features_valid_2, target_valid_2)\n",
    "predictions_2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lleva a cabo un entrenamiento de los 3 conjuntos de datos utilizando un modelo de regresión lineal. Posteriormente, se calcula el RMSE (Root Mean Squared Error) para cada área de pozos, con el objetivo de evaluar la precisión de las predicciones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volumen total de reservas en 200 pozos en data_0:  31102.330838811384\n",
      "Ganancia en los 200 pozos en data_0:  39960488.77465123\n",
      "\n",
      "\n",
      "Volumen total de reservas en 200 pozos en data_1:  27746.02678216344\n",
      "Ganancia en los 200 pozos en data_1:  24857120.519735485\n",
      "\n",
      "\n",
      "Volumen total de reservas en 200 pozos en data_2:  29603.89865831835\n",
      "Ganancia en los 200 pozos en data_2:  33217543.96243258\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ganacias 200 mejores pozos\n",
    "\n",
    "ingreso_unidad_producto= 4500\n",
    "costo_promedio_pozo= 100000000/200\n",
    "\n",
    "def calcular_ganancias(model, features_valid, target_valid):\n",
    "  \n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    \n",
    "    resultados = pd.DataFrame({\n",
    "        'predictions': predictions_valid,\n",
    "        'target': target_valid.reset_index(drop=True)\n",
    "    })\n",
    "    \n",
    "    # Seleccionar los 200 mejores pozos según predicción\n",
    "    top_200 = resultados.nlargest(200, 'predictions')\n",
    "    \n",
    "    # Calcular el volumen total predicho y la ganancia\n",
    "    volumen_total = top_200['predictions'].sum() \n",
    "    ganancia_total = volumen_total * ingreso_unidad_producto - (costo_promedio_pozo * 200)\n",
    "    \n",
    "    return volumen_total, ganancia_total\n",
    "\n",
    "# data_0\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(features_train_0, target_train_0)\n",
    "\n",
    "volumen_total, ganancia_total = calcular_ganancias(modelo, features_valid_0, target_valid_0)\n",
    "\n",
    "print('Volumen total de reservas en 200 pozos en data_0: ', volumen_total)\n",
    "print('Ganancia en los 200 pozos en data_0: ', ganancia_total)\n",
    "print('\\n')\n",
    "# data_1\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(features_train_1, target_train_1)\n",
    "\n",
    "volumen_total, ganancia_total = calcular_ganancias(modelo, features_valid_1, target_valid_1)\n",
    "\n",
    "print('Volumen total de reservas en 200 pozos en data_1: ', volumen_total)\n",
    "print('Ganancia en los 200 pozos en data_1: ', ganancia_total)\n",
    "print('\\n')\n",
    "      \n",
    "# data_2\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(features_train_2, target_train_2)\n",
    "\n",
    "volumen_total, ganancia_total = calcular_ganancias(modelo, features_valid_2, target_valid_2)\n",
    "\n",
    "print('Volumen total de reservas en 200 pozos en data_2: ', volumen_total)\n",
    "print('Ganancia en los 200 pozos en data_2: ', ganancia_total)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se calcula el volumen de reservas de los mejores 200 pozos por cada área de estudio. Además, se calcula la ganancia que se obtiene al evaluar los 200 pozos. Es importante destacar que el dataset data_0 presenta el mayor volumen de reservas, con 31.102 miles de barriles, y una ganancia cercana a los 40 millones de dólares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneficio promedio para data_0 es: 108219139.51966149\n",
      "Intervalo de confianza del 95%: para data_0 es: [1.03938754e+08 1.12798731e+08]\n",
      "Riesgo de pérdidas para data_0 es: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# # Bootstraping data_0\n",
    "\n",
    "n_boostrap = 1000\n",
    "n_sample = 500\n",
    "\n",
    "list_revenue_data_0 = []\n",
    "\n",
    "ingreso_unidad_producto= 4500\n",
    "costo_promedio_pozo= 100000000/200\n",
    "\n",
    "# Función para calcular la ganancia\n",
    "def calcular_revenue(sample):\n",
    "    volumen_total_sample = sample.sum()\n",
    "    ganancia_total_sample = volumen_total_sample * ingreso_unidad_producto - (costo_promedio_pozo * 200)\n",
    "    return ganancia_total_sample\n",
    "\n",
    "# Convertir predictions_0 a pandas.Series si es un numpy.ndarray\n",
    "if isinstance(predictions_0, np.ndarray):\n",
    "    predictions_0 = pd.Series(predictions_0)\n",
    "\n",
    "# Bucle para realizar el bootstrapping\n",
    "for i in range(n_boostrap):\n",
    "    # Muestreo con reposición\n",
    "    sample_bootstrap = predictions_0.sample(n=n_sample, replace=True)  # Uso de 'replace=True'\n",
    "    \n",
    "    # Calcular la ganancia total para la muestra\n",
    "    revenue_data_0 = calcular_revenue(sample_bootstrap)\n",
    "    \n",
    "    # Almacenar la ganancia en la lista\n",
    "    list_revenue_data_0.append(revenue_data_0)\n",
    "\n",
    "# Calcular el beneficio promedio y el intervalo de confianza\n",
    "ganancia_promedio = np.mean(list_revenue_data_0)\n",
    "intervalo_confianza = np.percentile(list_revenue_data_0, [2.5, 97.5])\n",
    "riesgo_de_perdidas = np.mean(np.array(list_revenue_data_0) < 0) * 100  # Riesgo de pérdidas\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Beneficio promedio para data_0 es:\", ganancia_promedio)\n",
    "print(\"Intervalo de confianza del 95%: para data_0 es:\", intervalo_confianza)\n",
    "print(\"Riesgo de pérdidas para data_0 es:\", riesgo_de_perdidas, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneficio promedio para data_1 es: 54755662.06353103\n",
      "Intervalo de confianza del 95%: para data_1 es: [45609661.70026577 63234865.81758487]\n",
      "Riesgo de pérdidas para data_1 es: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# # Bootstraping data_1\n",
    "\n",
    "n_boostrap = 1000\n",
    "n_sample = 500\n",
    "\n",
    "list_revenue_data_1 = []\n",
    "\n",
    "ingreso_unidad_producto= 4500\n",
    "costo_promedio_pozo= 100000000/200\n",
    "\n",
    "# Función para calcular la ganancia\n",
    "def calcular_revenue(sample):\n",
    "    volumen_total_sample = sample.sum()\n",
    "    ganancia_total_sample = volumen_total_sample * ingreso_unidad_producto - (costo_promedio_pozo * 200)\n",
    "    return ganancia_total_sample\n",
    "\n",
    "# Convertir predictions_0 a pandas.Series si es un numpy.ndarray\n",
    "if isinstance(predictions_1, np.ndarray):\n",
    "    predictions_1 = pd.Series(predictions_1)\n",
    "\n",
    "# Bucle para realizar el bootstrapping\n",
    "for i in range(n_boostrap):\n",
    "    # Muestreo con reposición\n",
    "    sample_bootstrap = predictions_1.sample(n=n_sample, replace=True)  # Uso de 'replace=True'\n",
    "    \n",
    "    # Calcular la ganancia total para la muestra\n",
    "    revenue_data_1 = calcular_revenue(sample_bootstrap)\n",
    "    \n",
    "    # Almacenar la ganancia en la lista\n",
    "    list_revenue_data_1.append(revenue_data_1)\n",
    "\n",
    "# Calcular el beneficio promedio y el intervalo de confianza\n",
    "ganancia_promedio = np.mean(list_revenue_data_1)\n",
    "intervalo_confianza = np.percentile(list_revenue_data_1, [2.5, 97.5])\n",
    "riesgo_de_perdidas = np.mean(np.array(list_revenue_data_1) < 0) * 100  # Riesgo de pérdidas\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Beneficio promedio para data_1 es:\", ganancia_promedio)\n",
    "print(\"Intervalo de confianza del 95%: para data_1 es:\", intervalo_confianza)\n",
    "print(\"Riesgo de pérdidas para data_1 es:\", riesgo_de_perdidas, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneficio promedio para data_2 es: 113735120.66897754\n",
      "Intervalo de confianza del 95%: para data_2 es: [1.09676226e+08 1.17967008e+08]\n",
      "Riesgo de pérdidas para data_2 es: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "# # Bootstraping data_2\n",
    "\n",
    "n_boostrap = 1000\n",
    "n_sample = 500\n",
    "\n",
    "list_revenue_data_2 = []\n",
    "\n",
    "ingreso_unidad_producto= 4500\n",
    "costo_promedio_pozo= 100000000/200\n",
    "\n",
    "# Función para calcular la ganancia\n",
    "def calcular_revenue(sample):\n",
    "    volumen_total_sample = sample.sum()\n",
    "    ganancia_total_sample = volumen_total_sample * ingreso_unidad_producto - (costo_promedio_pozo * 200)\n",
    "    return ganancia_total_sample\n",
    "\n",
    "# Convertir predictions_0 a pandas.Series si es un numpy.ndarray\n",
    "if isinstance(predictions_2, np.ndarray):\n",
    "    predictions_2 = pd.Series(predictions_2)\n",
    "\n",
    "# Bucle para realizar el bootstrapping\n",
    "for i in range(n_boostrap):\n",
    "    # Muestreo con reposición\n",
    "    sample_bootstrap = predictions_2.sample(n=n_sample, replace=True)  # Uso de 'replace=True'\n",
    "    \n",
    "    # Calcular la ganancia total para la muestra\n",
    "    revenue_data_2 = calcular_revenue(sample_bootstrap)\n",
    "    \n",
    "    # Almacenar la ganancia en la lista\n",
    "    list_revenue_data_2.append(revenue_data_2)\n",
    "\n",
    "# Calcular el beneficio promedio y el intervalo de confianza\n",
    "ganancia_promedio = np.mean(list_revenue_data_2)\n",
    "intervalo_confianza = np.percentile(list_revenue_data_2, [2.5, 97.5])\n",
    "riesgo_de_perdidas = np.mean(np.array(list_revenue_data_2) < 0) * 100  # Riesgo de pérdidas\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Beneficio promedio para data_2 es:\", ganancia_promedio)\n",
    "print(\"Intervalo de confianza del 95%: para data_2 es:\", intervalo_confianza)\n",
    "print(\"Riesgo de pérdidas para data_2 es:\", riesgo_de_perdidas, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al aplicar la técnica de bootstrapping, se evaluó el desempeño de cada área de estudio considerando el beneficio promedio, el riesgo de pérdida y el ancho del intervalo de confianza al 95%. Los resultados obtenidos indican que el área \"data_2\" presenta el mejor perfil, con un beneficio promedio de 113 millones de dólares y un riesgo de pérdida inferior al 1%. Este bajo riesgo, combinado con un alto beneficio esperado, sugiere un potencial de inversión muy atractivo para esta área."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basado en el análisis realizado, se recomienda priorizar el área data_2 para la exploración de los 200 pozos. Esta área presenta el mayor beneficio promedio, con un riesgo de pérdida prácticamente nulo y un costo de exploración estimado por debajo de los 100 millones de dólares. Aunque el área data_0 también ofrece un perfil atractivo, data_2 se destaca por su mayor potencial de retorno de inversión y menor incertidumbre asociada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
